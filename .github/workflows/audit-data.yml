name: Audit Data (PR)

on:
  pull_request:
    branches: [ main ]
    paths:
      - "output/**.csv"
      - ".github/workflows/run-scraper.yml"
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: audit-data-${{ github.ref }}
  cancel-in-progress: true

jobs:
  audit:
    if: github.event_name != 'pull_request' || github.head_ref == 'bot/scrape'
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout PR head
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Run audit
        id: audit
        run: |
          python - <<'PY'
          import csv, os, json, glob, sys

          REQUIRED = [
            "pubmed_eppley.csv",
            "crossref_works.csv",
            "openalex_works.csv",
            "orcid_profiles.csv",
            "orcid_works.csv",
            "youtube_all.csv",
            "wordpress_posts.csv",
            "clinical_trials.csv",
          ]
          MIN_ROWS = {
            "pubmed_eppley.csv": 50,
            "crossref_works.csv": 100,
            "openalex_works.csv": 50,
            "orcid_profiles.csv": 1,
            "orcid_works.csv": 100,
            "youtube_all.csv": 1,        # tighten later as needed
            "wordpress_posts.csv": 1,    # 0 means REST empty; sitemap fallback should fill
            "clinical_trials.csv": 1
          }

          out = {"files": []}
          base = "output"
          ok = True

          def count_rows(path):
            try:
              with open(path, newline='', encoding='utf-8', errors='ignore') as f:
                r = csv.reader(f)
                rows = sum(1 for _ in r) - 1
                return max(rows, 0)
            except FileNotFoundError:
              return -1

          for req in REQUIRED:
            p = os.path.join(base, req)
            rows = count_rows(p)
            exists = rows >= 0
            min_ok = rows >= MIN_ROWS.get(req, 0) if exists else False
            out["files"].append({
              "file": req, "exists": exists, "rows": rows, "min_ok": min_ok
            })
            if not exists or not min_ok:
              ok = False

          out["summary"] = {"ok": ok}
          os.makedirs("artifacts", exist_ok=True)
          with open("artifacts/audit.json","w",encoding="utf-8") as f:
            json.dump(out, f, indent=2)
          print(json.dumps(out, indent=2))
          if not ok:
            sys.exit(1)
          PY

      - name: Upload audit.json
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit.json
          path: artifacts/audit.json
          if-no-files-found: warn